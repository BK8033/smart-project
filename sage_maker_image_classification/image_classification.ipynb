{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolearn:aws:iam::334381301451:role/service-role/AmazonSageMaker-ExecutionRole-20190712T131802\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"role\" + role)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'ic-fulltraining'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:1\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification')\n",
    "print (training_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-334381301451/ic-fulltraining/train/\n",
      "s3://sagemaker-us-west-2-334381301451/ic-fulltraining/validation/\n",
      "s3://sagemaker-us-west-2-334381301451/ic-fulltraining/output\n"
     ]
    }
   ],
   "source": [
    "# Four channels: train, validation, train_lst, and validation_lst\n",
    "s3train = 's3://{}/{}/train/'.format(bucket, prefix)\n",
    "s3validation = 's3://{}/{}/validation/'.format(bucket, prefix)\n",
    "print(s3train)\n",
    "print(s3validation)\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print(s3_output_location)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p2.xlarge',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode = 'File',\n",
    "                                         output_path = s3_output_location,\n",
    "                                         sagemaker_session=sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.set_hyperparameters(num_layers=18,\n",
    "                             image_shape = \"1,350,360\",\n",
    "                             num_classes=2,\n",
    "                             num_training_samples=1200,\n",
    "                             mini_batch_size=10,\n",
    "                             epochs=5,\n",
    "                             learning_rate=0.01,\n",
    "                             top_k=2,\n",
    "                             precision_dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3train, distribution='FullyReplicated', \n",
    "                        content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3validation, distribution='FullyReplicated', \n",
    "                             content_type='application/x-recordio', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-06 01:46:55 Starting - Starting the training job...\n",
      "2019-08-06 01:46:57 Starting - Launching requested ML instances......\n",
      "2019-08-06 01:48:00 Starting - Preparing the instances for training.........\n",
      "2019-08-06 01:49:53 Downloading - Downloading input data\n",
      "2019-08-06 01:49:53 Training - Downloading the training image......\n",
      "2019-08-06 01:50:52 Training - Training image download completed. Training in progress..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.01', u'top_k': u'2', u'precision_dtype': u'float32', u'epochs': u'5', u'num_training_samples': u'1200', u'num_layers': u'18', u'mini_batch_size': u'10', u'image_shape': u'1,350,360', u'num_classes': u'2'}\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] Final configuration: {u'top_k': u'2', u'optimizer': u'sgd', u'learning_rate': u'0.01', u'epochs': u'5', u'lr_scheduler_factor': 0.1, u'num_layers': u'18', u'precision_dtype': u'float32', u'mini_batch_size': u'10', u'num_classes': u'2', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': 0, u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'1,350,360', u'gamma': 0.9, u'num_training_samples': u'1200'}\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] Searching for .rec files in /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] Searching for .rec files in /opt/ml/input/data/validation.\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] use_pretrained_model: 0\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] multi_label: 0\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] Performing random weight initialization\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] ---- Parameters ----\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] num_layers: 18\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] epochs: 5\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] optimizer: sgd\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] momentum: 0.9\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] learning_rate: 0.01\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] num_training_samples: 1200\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] mini_batch_size: 10\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] image_shape: 1,350,360\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] num_classes: 2\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] augmentation_type: None\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] kv_store: device\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] top_k: 2\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] --------------------\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:50:54 INFO 139867713042240] Setting number of threads: 3\u001b[0m\n",
      "\u001b[31m[01:51:01] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-master.883.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:08 INFO 139867713042240] Epoch[0] Batch [20]#011Speed: 28.463 samples/sec#011accuracy=0.976190#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:11 INFO 139867713042240] Epoch[0] Batch [40]#011Speed: 37.348 samples/sec#011accuracy=0.985366#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:15 INFO 139867713042240] Epoch[0] Batch [60]#011Speed: 41.625 samples/sec#011accuracy=0.990164#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:19 INFO 139867713042240] Epoch[0] Batch [80]#011Speed: 44.198 samples/sec#011accuracy=0.990123#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:22 INFO 139867713042240] Epoch[0] Batch [100]#011Speed: 45.910 samples/sec#011accuracy=0.992079#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:26 INFO 139867713042240] Epoch[0] Train-accuracy=0.993333\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:26 INFO 139867713042240] Epoch[0] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:26 INFO 139867713042240] Epoch[0] Time cost=25.305\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:29 INFO 139867713042240] Epoch[0] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:29 INFO 139867713042240] Storing the best model with validation accuracy: 1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:29 INFO 139867713042240] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:34 INFO 139867713042240] Epoch[1] Batch [20]#011Speed: 45.021 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:37 INFO 139867713042240] Epoch[1] Batch [40]#011Speed: 49.104 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:41 INFO 139867713042240] Epoch[1] Batch [60]#011Speed: 50.516 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:45 INFO 139867713042240] Epoch[1] Batch [80]#011Speed: 51.288 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:48 INFO 139867713042240] Epoch[1] Batch [100]#011Speed: 51.787 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:52 INFO 139867713042240] Epoch[1] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:52 INFO 139867713042240] Epoch[1] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:52 INFO 139867713042240] Epoch[1] Time cost=22.833\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:55 INFO 139867713042240] Epoch[1] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:51:59 INFO 139867713042240] Epoch[2] Batch [20]#011Speed: 47.055 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:03 INFO 139867713042240] Epoch[2] Batch [40]#011Speed: 50.150 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:07 INFO 139867713042240] Epoch[2] Batch [60]#011Speed: 51.237 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:10 INFO 139867713042240] Epoch[2] Batch [80]#011Speed: 51.853 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:14 INFO 139867713042240] Epoch[2] Batch [100]#011Speed: 52.224 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:18 INFO 139867713042240] Epoch[2] Train-accuracy=0.999167\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:18 INFO 139867713042240] Epoch[2] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:18 INFO 139867713042240] Epoch[2] Time cost=22.699\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:20 INFO 139867713042240] Epoch[2] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:25 INFO 139867713042240] Epoch[3] Batch [20]#011Speed: 47.372 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:29 INFO 139867713042240] Epoch[3] Batch [40]#011Speed: 50.352 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:32 INFO 139867713042240] Epoch[3] Batch [60]#011Speed: 51.298 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:36 INFO 139867713042240] Epoch[3] Batch [80]#011Speed: 51.815 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:40 INFO 139867713042240] Epoch[3] Batch [100]#011Speed: 52.150 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[08/06/2019 01:52:43 INFO 139867713042240] Epoch[3] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:43 INFO 139867713042240] Epoch[3] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:43 INFO 139867713042240] Epoch[3] Time cost=22.736\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:46 INFO 139867713042240] Epoch[3] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:51 INFO 139867713042240] Epoch[4] Batch [20]#011Speed: 47.152 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:54 INFO 139867713042240] Epoch[4] Batch [40]#011Speed: 50.020 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:52:58 INFO 139867713042240] Epoch[4] Batch [60]#011Speed: 50.961 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:53:02 INFO 139867713042240] Epoch[4] Batch [80]#011Speed: 51.548 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:53:06 INFO 139867713042240] Epoch[4] Batch [100]#011Speed: 51.879 samples/sec#011accuracy=1.000000#011top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:53:09 INFO 139867713042240] Epoch[4] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:53:09 INFO 139867713042240] Epoch[4] Train-top_k_accuracy_2=1.000000\u001b[0m\n",
      "\u001b[31m[08/06/2019 01:53:09 INFO 139867713042240] Epoch[4] Time cost=22.851\u001b[0m\n",
      "\n",
      "2019-08-06 01:53:25 Uploading - Uploading generated training model\n",
      "2019-08-06 01:53:25 Completed - Training job completed\n",
      "\u001b[31m[08/06/2019 01:53:12 INFO 139867713042240] Epoch[4] Validation-accuracy=1.000000\u001b[0m\n",
      "Billable seconds: 239\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ic.fit(inputs=data_channels, logs=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??......!"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "optimized_ic = ic\n",
    "try:\n",
    "    ic.create_model()._neo_image_account(boto3.Session().region_name)\n",
    "except:\n",
    "    print('Neo is not currently supported in', boto3.Session().region_name)\n",
    "else:\n",
    "    output_path = '/'.join(ic.output_path.split('/')[:-1])\n",
    "    optimized_ic = ic.compile_model(target_instance_family='ml_m4', \n",
    "                                input_shape={'data':[1, 1, 350, 360]},  # Batch size 1, 3 channels, 224x224 Images.\n",
    "                                output_path=output_path,\n",
    "                                framework='mxnet', framework_version='1.2.1')\n",
    "    optimized_ic.image = get_image_uri(sess.boto_region_name, 'image-classification-neo', repo_version=\"latest\")\n",
    "    optimized_ic.name = 'deployed-image-classification'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: deployed-image-classificationml-t2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "ic_classifier = optimized_ic.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.t2.medium')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lst =[]\n",
    "file_lst.append('cutted_img_0007.jpg')\n",
    "file_lst.append('cutted_img_0008.jpg')\n",
    "file_lst.append('cutted_img_0009.jpg')\n",
    "file_lst.append('cutted_img_0010.jpg')\n",
    "file_lst.append('cutted_img_6.jpg')\n",
    "file_lst.append('cutted_img_7.jpg')\n",
    "file_lst.append('cutted_img_8.jpg')\n",
    "file_lst.append('cutted_img_9.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 7.775905693749768e-21]\n",
      "Result: label - abnormal, probability - 1.0\n",
      "\n",
      "\n",
      "[1.0, 6.749181814026387e-20]\n",
      "Result: label - abnormal, probability - 1.0\n",
      "\n",
      "\n",
      "[1.0, 2.8317375145436087e-21]\n",
      "Result: label - abnormal, probability - 1.0\n",
      "\n",
      "\n",
      "[1.0, 9.847611041837937e-20]\n",
      "Result: label - abnormal, probability - 1.0\n",
      "\n",
      "\n",
      "[0.08254571259021759, 0.9174543619155884]\n",
      "Result: label - normal, probability - 0.9174543619155884\n",
      "\n",
      "\n",
      "[0.047843821346759796, 0.952156126499176]\n",
      "Result: label - normal, probability - 0.952156126499176\n",
      "\n",
      "\n",
      "[0.115699402987957, 0.8843005895614624]\n",
      "Result: label - normal, probability - 0.8843005895614624\n",
      "\n",
      "\n",
      "[0.993401825428009, 0.006598117295652628]\n",
      "Result: label - abnormal, probability - 0.993401825428009\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "for file_name in file_lst: \n",
    "    with open(file_name, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "        ic_classifier.content_type = 'application/x-image'\n",
    "        result = json.loads(ic_classifier.pr,edict(payload))\n",
    "        print(result)\n",
    "        index = np.argmax(result)\n",
    "        object_categories = ['abnormal','normal']\n",
    "        print(\"Result: label - \" + object_categories[index] + \", probability - \" + str(result[index]))\n",
    "        print()\n",
    "        print()\n",
    "\n",
    "# the result will output the probabilities for all classes\n",
    "# find the class with maximum probability and print the class index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
